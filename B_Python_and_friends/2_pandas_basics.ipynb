{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Copyright (c) 2019 OERCompBiomed (UiB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-commentate"
    ]
   },
   "source": [
    "<h1 style=\"color:blue\">Pandas</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "\n",
    "NOTE: The original notebook on Github might change over the time, and we recommend that you make a copy of our notebooks before you are editing them. In this respect you might adopt the naming convention my_<'name_of_notebook'>.ipynb, e.g. `my_2_pandas_basics.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You are encouraged to experiment with all our code!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "## Import libraries<a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Python has many available functions and classes. Some of these functions are only accessible through importing specialized modules. **Library** is an umbrella term referring to reusable chunk of code. Let's say you wish to do math operations. We use the `import` to make the math functions available: \n",
    "\n",
    "`import math`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[*Pandas*](https://pandas.pydata.org)__ is the premier Python package for data analysis. Pandas is built around the concept of *series* (akin to Numpy vectors) and *data frames* (akin to Numpy matrices). Unlike their Numpy counterparts, Pandas has a rich API that often makes series and data frames more convenient to work with.\n",
    "\n",
    "First though, let's import Pandas. Conventionally it is given the name `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we usually import pandas\n",
    "import pandas as pd \n",
    "\n",
    "# We can also import specific functions in a library: \n",
    "from pandas import DataFrame, read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that pandas is imported, its functions can be used like this:\n",
    "\n",
    "`pd.functionName()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import all other helpful libraries needed for the tutorial\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np #this is how we usually import numpy\n",
    "import sys #only needed to determine Python version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress some warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# We can print versions of packages\n",
    "print('Python version ' + sys.version)\n",
    "print('Pandas version ' + pd.__version__)\n",
    "print('Numpy version ' + np.__version__)\n",
    "print('Seaborn version ' + sns.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-commentate"
    ]
   },
   "source": [
    "# PART I <a name=\"part1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "## Iris flower data <a name=\"irisdata\"></a>\n",
    "https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./assets/iris_data_intro.png' alt=\"iris_data_intro\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Set Information:**\n",
    "\n",
    "This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. \n",
    "\n",
    "Predicted attribute: class of iris plant. \n",
    "\n",
    "This is an exceedingly simple domain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attribute Information:**\n",
    "\n",
    "1. sepal length in cm \n",
    "2. sepal width in cm \n",
    "3. petal length in cm \n",
    "4. petal width in cm \n",
    "5. class: <br>\n",
    "-- Iris Setosa <br>\n",
    "-- Iris Versicolour <br>\n",
    "-- Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read local data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('./data/iris.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Data exploration in Pandas <a name=\"dataexploration\"></a>\n",
    "\n",
    "The first thing we usually do after loading a dataframe (i.e. table), is to inspect it using the following methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we have 150 samples (rows) and 5 features per sample (columns). What are those features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in iris.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display your samples\n",
    "Display the 5 first rows using `df.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the 10 first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now you should know that the input to the `head` function is an optional parameter which defaults to 5. You can confirm this by writing `iris.head()` and pressing Shift+Tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or the 5 last using `df.tail()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary can be presented with `df.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see the data types each column contains too: the measurements are `float64`, which means 64 bit floating point (decimal) numbers. The *Name* feature is a string, which in pandas terms is an `object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# another way to access the datatypes\n",
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `df.describe()` will print a summary of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "\n",
    "<h4>Exercise 1.</h4>\n",
    "Imagine you are given some data in a table from your supervisor. You are told this contains 50 physical measurements from a total of 1400 E. *coli* cells. Also you know your supervisor has a messy file system, and easily confuses filenames between different projects. How would you assure that you have been given the right dataset?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Accessing specific rows and columns <a name=\"accessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing pandas dataframes is done by using either of two methods: `.iloc` and `.loc`. Let's start with the former. which is purely number-based. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB: Remember Python starts counting at 0!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the 4th row of the 2rd column:\n",
    "\n",
    "iris.iloc[3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head(4) #checks out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing also works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 4 rows and 2nd column\n",
    "iris.iloc[:4, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "\n",
    "<h4>Exercise 2.</h4> \n",
    "We can also pass in arrays or lists to access particular rows and columns. Try to do this to obtain only rows numbered 0, 10, 20 and 30 (and all columns).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this should act more or less the way you have seen indexing before. `.loc` is slightly different, because it allows you to use **column names** as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[:3, 'SepalWidth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing in a list of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[147:, ['SepalWidth', 'PetalLength']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "\n",
    "<h4>Exercise 3.</h4> What species is the 10th, 50th and 100th flower?\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also access a single column by writing `iris.column_name`, which is can save you some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.SepalWidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boolean indexing\n",
    "\n",
    "The dataframes contents can be accessed by passing in a list (or equivalent) of the same length as the dataframe, with boolean entries. For instance `df.iloc[[False, True, True...], :]` would not return the first sample, but the second and third... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the flowers with a sepal length greater than 5 cm\n",
    "iris.SepalLength >= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to obtain only a subset of rows with a feature of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenghtySepals = iris.SepalLength >= 5   \n",
    "iris.loc[lenghtySepals,'SepalLength']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "<h4> Exercise 4. </h4>\n",
    " a) Obtain only the rows in which the sepalWidth is greater than average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "Hint: you can make use of the `.mean()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.SepalWidth.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex4 a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "b) How many such samples are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_4ab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "c) only the colums which are of datatype `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_4c.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "d) Use what you know to count the number of samples from each of the species. Are they balanced?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_4d.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative to boolean indexing, you can use `.query`, so the following are equivalent: \n",
    "\n",
    "```python\n",
    "iris.loc[iris.Name == 'Iris-setosa', :]\n",
    "iris.query('Name == \"Iris-setosa\"')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Manipulating dataframes <a name=\"manipulating\"></a>\n",
    "\n",
    "Before we proceed you should know the basics of removing and adding rows or columns. To remove, we use the `.drop()` method, and to add, we can use `.append()`. By default, the changes are not in place, but returns a copy of the dataframe. To make the change, we have to set `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROWS\n",
    "iris.drop(index=[0,2,4,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLS\n",
    "iris.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we used keyword arguments, but we could also use positional arguments, and also specify the axis (0 for rows, 1 for columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new row:\n",
    "\n",
    "test_row = {'SepalLength':0, 'SepalWidth':0, 'PetalLength':0, 'PetalWidth':0, 'Name':'test'}\n",
    "test_row\n",
    "\n",
    "# we use double square brackets [[]] to ensure it is interpreted as a row and not a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add test row to tail of iris dataframe\n",
    "iris.append(test_row, ignore_index=True).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, changing a entries can be done simply by using the `.loc` or `.iloc` attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "## Create a table from data\n",
    "\n",
    "We now want to recreate a table from an old paper based on the same dataset. First, let us import an image from the paper:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./assets/iris_data_tabular.png' alt=\"disease network\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table in the image is sorted into three tables based on the name of the flower. Each table then present the values from the other four columns. We therefore start by sorting them based on their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setosa = iris[iris.Name == 'Iris-setosa'].drop(['Name'], axis=1)\n",
    "versicolor = iris[iris.Name == 'Iris-versicolor'].drop(['Name'], axis=1)\n",
    "virginica = iris[iris.Name == 'Iris-virginica'].drop(['Name'], axis=1)\n",
    "\n",
    "n = len(setosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then print each table using a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t   Iris setosa', '     Iris versicolor', '  Iris virginica')\n",
    "for k in range(n):\n",
    "    print(k+1, '\\t', setosa.values[k,:], versicolor.values[k,:], virginica.values[k,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access a group of values according to column names using `.loc` and matrix transpose (`.T`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setosa.loc[:,['SepalLength','SepalWidth', 'PetalLength', 'PetalWidth']].T\n",
    "setosa.loc[:,['SepalLength','SepalWidth']].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graphs from data\n",
    "\n",
    "Plotting in python is usually done through **matplotlib's pyplot**, which we will use later on, but we can use pandas' API for this:\n",
    "We can make subplots plotting values from different columns against each other like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.plot.scatter('SepalLength', 'SepalWidth')\n",
    "\n",
    "iris.plot.scatter('PetalLength', 'PetalWidth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you make some observations from these plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting using seaborn __[pairplot](https://seaborn.pydata.org/generated/seaborn.pairplot.html)__**<br>\n",
    "\n",
    "\n",
    "## Plotting with Seaborn\n",
    "The Seaborn library deals smoothly with pandas dataframes, and the plots are more visually appealing. Let's plot each species in a different color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(iris, height=6, x_vars=[\"SepalLength\"], y_vars=[\"SepalWidth\"], hue=\"Name\",\n",
    "                 markers=[\"s\", \"o\", \"D\"])\n",
    "\n",
    "# hue determines which column is to be used to define color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or pairplots as a matrix plot with color-encoded class-specific histograms on the diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(iris, vars=[\"SepalLength\", \"SepalWidth\"], hue=\"Name\", diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and with color-coded class-specific [KDE](https://en.wikipedia.org/wiki/Kernel_density_estimation)-estimated probability densities on the diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(iris, hue=\"Name\", palette=\"husl\",  markers=[\"s\", \"o\", \"D\"], diag_kind=\"kde\")\n",
    "# not specifying the columns automatically uses all of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** \n",
    " - **Which one of three flowers is easiest to differentiate from the other two flowers based on its Sepal and Petal measurements ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Statistics using Pandas <a name=\"statistics\"></a>\n",
    "\n",
    "Let us again look at the seminal Fisher [article](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x) based on this data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/iris_data_statistics.png\" alt=\"disease network\" width=\"900\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.describe()` to calculate simple **descriptive statistics** for the dataset (rounding to 3 decimals):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe().round(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the **pairwise correlation of columns** (features) using `.corr()`. Variations of correlation measure is also adjustable (e.g. ‘pearson’ (default), ‘kendall’, or ‘spearman’) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.corr().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including only string columns in a DataFrame description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# like we explained above, object in this case means text\n",
    "iris.describe(include=[np.object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case same as excluding numeric columns from a DataFrame description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe(exclude=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get statistical values for the different types of iris flowers we can split the object (iris DataFrame) into groups (species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = iris.groupby('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the group-wise `PetalLength` summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PetalLength:')\n",
    "grouped['PetalLength'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through the grouped data is very natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, group in grouped:\n",
    "    print(name,':')\n",
    "    print(group.describe().round(2).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group-wise feature correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris.groupby('Name').corr().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame has an `assign()` method that allows you to easily create new columns that are potentially derived from existing columns. Here we add a columns with the ratio between SepalWidth and SepalLength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iris.assign(sepal_ratio = iris['SepalWidth'] / iris['SepalLength']).head().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`assign` always returns a copy of the data, leaving the original DataFrame untouched, e.g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "<h4>Digression: lambda functions</h4>\n",
    "\n",
    "Lambda functions (anonymous functions) are equivalent to regular functions, only the syntax is different. We only make use of them if we need a function once. Thus the two below functions are equivalent\n",
    "\n",
    "```python\n",
    "def add_one(a): return a + 1\n",
    "\n",
    "add_one = lambda a : a + 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "<h4>Exercise 5.</h4>Make a new column which is the sum of all the measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing a callable, as opposed to an actual value to be inserted, is useful when you don’t have a reference to the DataFrame at hand. This is common when using `assign`  in a chain of operations. For example, we can limit the DataFrame to just those observations with a Sepal Length greater than 5, calculate the ratio, and plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(iris.query('SepalLength > 5')\n",
    " .assign(SepalRatio = lambda x: x.SepalWidth / x.SepalLength,\n",
    "         PetalRatio = lambda x: x.PetalWidth / x.PetalLength)\n",
    " .plot(kind='scatter', x='SepalRatio', y='PetalRatio'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "<h4>Exercise 6.</h4> Compute the mean and standard deviation of the SepalWidth / SepalLength ratio.\n",
    "\n",
    "Hint: use the Tab trick to find the relevant methods, or just make an online search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_6.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-commentate"
    ]
   },
   "source": [
    "# PART 2 - extra stuff <a name=\"part2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part I you learned about some basic functionalities, how to access contents from your dataframe, indexing, grouping, and how to modify it, making quick plots and even how to create new features based on old ones. In this section, we will go through much of the same material, but more bottom-up, from the very simple data structures to how to efficiently work with them. There will then be some overlap in the material.\n",
    "\n",
    "<br>- taken from \"10 Minutes to pandas\"\n",
    "(https://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "\n",
    "You can see more complex recipes in the __[Cookbook](https://pandas.pydata.org/pandas-docs/stable/cookbook.html)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Object creation <a name=\"objectcreation\"></a>\n",
    "\n",
    "See also __[Intro to Data Structures](https://pandas.pydata.org/pandas-docs/stable/dsintro.html)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have looked at dataframes. These are analogous to (2D) matrices. The analogy to (1D) vectors are\n",
    "__[Series](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html)__ : a labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index. \n",
    "Creating a Series by passing a list of values, letting pandas create a default integer index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,3,5,np.nan,6,8])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a __[DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)__ by passing a NumPy array, with a datetime index and labeled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame** is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used pandas object. Like Series, DataFrame accepts many different kinds of input:\n",
    "\n",
    " - Dict of 1D ndarrays, lists, dicts, or Series\n",
    " - 2-D numpy.ndarray\n",
    " - [Structured or record ndarray](https://docs.scipy.org/doc/numpy/user/basics.rec.html)\n",
    " - A `Series`\n",
    " - Another `DataFrame`\n",
    " \n",
    "Along with the data, you can optionally pass **index** (row labels) and **columns** (column labels) arguments. If you pass an index and / or columns, you are guaranteeing the index and / or columns of the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a DataFrame by passing a dict of objects that can be converted to series-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({ 'A' : 1.,\n",
    "                    'B' : pd.Timestamp('20130102'),\n",
    "                    'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n",
    "                    'D' : np.array([3] * 4,dtype='int32'),\n",
    "                    'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n",
    "                    'F' : 'foo' })\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the resulting DataFrame have different dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’re using IPython (Jupyter notebook), tab completion for column names (as well as public attributes) is automatically enabled, ie.  df2.`<TAB>` <br> Here’s a subset of the attributes that will be completed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df2.<TAB>\n",
    "\n",
    " df2.A     df2.E       df2.add            df2.aggregate   df2.append        df2.as_matrix\n",
    " df2.B     df2.F       df2.add_prefix     df2.align       df2.apply         df2.asfreq\n",
    " df2.C     df2.T       df2.add_suffix     df2.all         df2.applymap      df2.asof       >  \n",
    " df2.D     df2.abs     df2.agg            df2.any         df2.as_blocks     df2.assign\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the columns `A`, `B`, `C`, and `D` are automatically tab completed. `E` is there as well; the rest of the attributes have been truncated for brevity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Viewing Data <a name=\"viewing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to view the top and bottom rows of the frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the index, columns, and the underlying NumPy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`describe()` shows a quick statistic summary of your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Selection <a name=\"selection\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also the indexing documentation __[Indexing and Selecting Data](https://pandas.pydata.org/pandas-docs/stable/indexing.html)__ \n",
    "and  __[MultiIndex / Advanced Indexing](https://pandas.pydata.org/pandas-docs/stable/advanced.html)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a single column, which yields a Series, equivalent to `df.A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting via `[]`, which slices the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection by Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more, see __[Selection by Label](https://pandas.pydata.org/pandas-docs/stable/indexing.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For getting a cross section using a label\n",
    "\n",
    "df.loc[dates[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting on a multi-axis by label\n",
    "\n",
    "df.loc[:,['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing label slicing, both endpoints are included\n",
    "\n",
    "df.loc['20130102':'20130104',['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction in the dimensions of the returned object\n",
    "\n",
    "df.loc['20130102',['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For getting a scalar value\n",
    "\n",
    "df.loc[dates[0],'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For getting fast access to a scalar (equivalent to the prior method)\n",
    "\n",
    "df.at[dates[0],'A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection by Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See more in __[Selection by Position](https://pandas.pydata.org/pandas-docs/stable/indexing.html)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select via the position of the passed integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By integer slices, acting similar to numpy/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3:5,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By lists of integer position locations, similar to the numpy/python style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1,2,4],[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For slicing rows explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For slicing columns explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For getting a value explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For getting fast access to a scalar (equivalent to the prior method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a single column’s values to select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.A > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting values from a DataFrame where a boolean condition is met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `isin()` method for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2['E'] = ['one', 'one','two','three','four','three']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['E'].isin(['two','four'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a new column automatically aligns the data by the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range('20130102', periods=6))\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['F'] = s1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting values by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[dates[0],'A'] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting values by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iat[0,1] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting by assigning with a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'D'] = np.array([5] * len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the prior setting operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `where` operation with setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[df2 > 0] = -df2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Missing data <a name=\"missing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas primarily uses the value `np.nan` to represent missing data. It is by default not included in computations. See the __[Missing Data section](https://pandas.pydata.org/pandas-docs/stable/missing_data.html)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
    "df1.loc[dates[0]:dates[1],'E'] = 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drop any rows that have missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.fillna(value=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the boolean mask where values are `nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Operations <a name=\"operations\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the __[Basic section on Binary Ops](https://pandas.pydata.org/pandas-docs/stable/basics.html)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations in general *exclude* missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a descriptive statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same operation on the other axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operating with objects that have different dimensionality and need alignment. In addition, pandas automatically broadcasts along the specified dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sub(s, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying functions to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogramming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See more at __[Histogramming and Discretization](https://pandas.pydata.org/pandas-docs/stable/basics.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randint(0, 7, size=10)); s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series is equipped with a set of string processing methods in the str attribute that make it easy to operate on each element of the array, as in the code snippet below. Note that pattern-matching in str generally uses regular expressions by default (and in some cases always uses them). <br>\n",
    "See more at __[Vectorized String Methods](https://pandas.pydata.org/pandas-docs/stable/text.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])\n",
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Merging  <a name=\"merging\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas provides various facilities for easily combining together Series, DataFrame, and Panel objects with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.<br>\n",
    "See the __[Merging section](https://pandas.pydata.org/pandas-docs/stable/merging.html)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating pandas objects together with `concat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4)); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break it into pieces\n",
    "pieces = [df[:3], df[3:7], df[7:]]\n",
    "pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.concat(pieces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL style merges. See the __[Database style joining](https://pandas.pydata.org/pandas-docs/stable/merging.html)__ section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['bar', 'foo'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'bar','bar'], 'rval': [4, 5, 6]})\n",
    "\n",
    "print('left:\\n', left)\n",
    "print('\\nright:\\n', right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append rows to a dataframe. See the __[Appending](https://pandas.pydata.org/pandas-docs/stable/merging.html)__ section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D']); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.iloc[3]; s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.append(s, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Grouping  <a name=\"grouping\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By “group by” we are referring to a process involving one or more of the following steps:\n",
    "\n",
    " - **Splitting** the data into groups based on some criteria\n",
    " - **Applying** a function to each group independently\n",
    " - **Combining** the results into a data structure\n",
    "\n",
    "See the __[Grouping section](https://pandas.pydata.org/pandas-docs/stable/groupby.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
    "                          'foo', 'bar', 'foo', 'foo'],\n",
    "                   'B' : ['one', 'one', 'two', 'three',\n",
    "                          'two', 'two', 'one', 'three'],\n",
    "                   'C' : np.random.randn(8),\n",
    "                   'D' : np.random.randn(8)})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping and then applying the `min()` function to the resulting groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('A').min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by multiple columns forms a hierarchical index, and again we can apply the `min()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['A','B']).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Reshaping  <a name=\"reshaping\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the sections on __[Hierarchical Indexing](https://pandas.pydata.org/pandas-docs/stable/advanced.html#advanced-hierarchical)__ and __[Reshaping](https://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-stacking)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n",
    "                      'foo', 'foo', 'qux', 'qux'],\n",
    "                     ['one', 'two', 'one', 'two',\n",
    "                      'one', 'two', 'one', 'two']]))\n",
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B']); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[:4]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __[stack()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.stack.html#pandas.DataFrame.stack)__ method “compresses” a level in the DataFrame’s columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = df2.stack()\n",
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a “stacked” DataFrame or Series (having a MultiIndex as the index), the inverse operation of stack() is __[unstack()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack)__, which by default unstacks the **last level**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.unstack(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivot Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the section on __[Pivot Tables](https://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-pivot)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3,\n",
    "                    'B' : ['A', 'B', 'C'] * 4,\n",
    "                    'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "                    'D' : np.random.randn(12),\n",
    "                    'E' : np.random.randn(12)})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can produce pivot tables from this data very easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Time Series <a name=\"timeseries\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has simple, powerful, and efficient functionality for performing resampling operations during frequency conversion (e.g., converting secondly data into 5-minutely data). This is extremely common in, but not limited to, financial applications. See the __[Time Series section](https://pandas.pydata.org/pandas-docs/stable/timeseries.html#timeseries)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range('1/1/2012', periods=100, freq='S'); rng[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng); ts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.resample('5Min').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time zone representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D'); rng[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(len(rng)), rng); ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_utc = ts.tz_localize('UTC')\n",
    "ts_utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to another time zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_utc.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting between time span representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range('1/1/2012', periods=5, freq='M'); rng[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(len(rng)), index=rng); ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = ts.to_period(); ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.to_timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting between period and timestamp enables some convenient arithmetic functions to be used. In the following example, we convert a quarterly frequency with year ending in November to 9am of the end of the month following the quarter end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV'); prng[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(len(prng)), prng); ts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Categoricals <a name=\"categoricals\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can include categorical data in a `DataFrame`. For full docs, see the __[categorical introduction](https://pandas.pydata.org/pandas-docs/stable/categorical.htm)__ and the __[API documentation](https://pandas.pydata.org/pandas-docs/stable/api.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"id\":[1,2,3,4,5,6], \"raw_grade\":['a', 'b', 'b', 'a', 'a', 'e']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the raw grades to a categorical data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the categories to more meaningful names (assigning to `Series.cat.categories` is inplace!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"grade\"].cat.categories = [\"very good\", \"good\", \"very bad\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the categories and simultaneously add the missing categories (methods under `Series .cat` return a new `Series` by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\", \"medium\", \"good\", \"very good\"])\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting is per order in the categories, not lexical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"grade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by a categorical column also shows empty categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"grade\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Plotting <a name=\"plotting\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the __[Plotting docs](https://pandas.pydata.org/pandas-docs/stable/visualization.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n",
    "ts = ts.cumsum()\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a DataFrame, the `plot()` method is a convenience to plot all of the columns with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,\n",
    "columns=['A', 'B', 'C', 'D']) \n",
    "\n",
    "df = df.cumsum()\n",
    "plt.figure(); df.plot(); plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "### Getting Data In/Out <a name=\"datainout\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables # pytables is needed to read and write hdf5 files\n",
    "import openpyxl # is used to read and write MS Excel files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Writing to a csv file`](https://pandas.pydata.org/pandas-docs/stable/io.html#io-store-in-csv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./testdata/foo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Reading from a csv file`](https://pandas.pydata.org/pandas-docs/stable/io.html#io-read-csv-table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./testdata/foo.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get help on __read_csv__, type: `read_csv?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and writing to [`HDFStores`](https://pandas.pydata.org/pandas-docs/stable/io.html#io-hdf5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to a HDF5 Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytables is needed\n",
    "df.to_hdf('./testdata/foo.h5','df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from a HDF5 Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_hdf('./testdata/foo.h5','df').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and writing to [`MS Excel`](https://pandas.pydata.org/pandas-docs/stable/io.html#io-excel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openpyxl is needed\n",
    "df.to_excel('./testdata/foo.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('./testdata/foo.xlsx', 'Sheet1', index_col=None, na_values=['NA']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "## Going further <a name=\"going\"></a>\n",
    "\n",
    "-  A handy Pandas *cheat sheet*:  http://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
    "-  Pandas: .head() to .tail() https://www.youtube.com/watch?v=7vuO9QXDN50  (1:26) <br> \n",
    "    w/GitHub repo: https://github.com/TomAugspurger/pydata-chi-h2t\n",
    "-  Very instructive tutorials:  http://pandas.pydata.org/pandas-docs/stable/tutorials.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
