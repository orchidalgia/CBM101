{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-commentate"
    ]
   },
   "source": [
    "# Open datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquiring Data from open repositories\n",
    "\n",
    "A crucial step in the work of a computational biologist is not only to analyse data, but acquiring datasets to analyse as well as toy datasets to test out computational methods and algorithms. The internet is full of such open datasets. Sometimes you have to sign up and make a user to get authentication, especially for medical data. This can sometimes be time consuming, so here we will deal with easy access resources, mostly of modest size. Multiple python libraries provide a `dataset` module which makes the effort to fetch online data extremely seamless, with little requirement for preprocessing.\n",
    "\n",
    "\n",
    "### Goal of the notebook\n",
    "\n",
    "Here you will get familiar with some ways to fetch datasets from online. We do some data exploration on the data just for illustration, but the methods will be covered later.\n",
    "\n",
    "\n",
    "# Useful resources and links\n",
    "\n",
    "When playing around with algorithms, it can be practical to use relatively small datasets. A good example is the `datasets` submodule of `scikit-learn`. `Nilearn` (library for neuroimaging) also provides a collection of neuroimaging datasets. Many datasets can also be acquired through the competition website [Kaggle](https://www.kaggle.com), in which they describe how to access the data.\n",
    "\n",
    "\n",
    "### Links\n",
    "- [OpenML](https://www.openml.org/search?type=data)\n",
    "- [Nilearn datasets](https://nilearn.github.io/modules/reference.html#module-nilearn.datasets)\n",
    "- [Sklearn datasets](https://scikit-learn.org/stable/modules/classes.html?highlight=datasets#module-sklearn.datasets)\n",
    "- [Kaggle](https://www.kaggle.com/datasets)\n",
    "- [MEDNIST]\n",
    "\n",
    "-  [**Awesomedata**](https://github.com/awesomedata/awesome-public-datasets)\n",
    "\n",
    " - We strongly recommend to check out the Awesomedata lists of public datasets, covering topics such as [biology/medicine](https://github.com/awesomedata/awesome-public-datasets#biology) and [neuroscience](https://github.com/awesomedata/awesome-public-datasets#neuroscience)\n",
    "\n",
    "- [Papers with code](https://paperswithcode.com)\n",
    "\n",
    "- [SNAP](https://snap.stanford.edu/data/)\n",
    "  - Stanford Large Network Dataset Collection  \n",
    "- [Open Graph Benchmark (OGB)](https://github.com/snap-stanford/ogb)\n",
    "  - Network datasets\n",
    "- [Open Neuro](https://openneuro.org/)\n",
    "- [Open fMRI](https://openfmri.org/dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with scikit-learn's datasets for testing out Machine Learning (ML) algorithms. Visit [here](https://scikit-learn.org/stable/modules/classes.html?highlight=datasets#module-sklearn.datasets) for an overview of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiple datasets from sklearn package\n",
    "from sklearn.datasets import fetch_olivetti_faces, fetch_20newsgroups, load_breast_cancer, load_diabetes, load_digits, load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Hand written digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset that consists of images of hand written digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data (pixels) to X and target (the number image presents) to y\n",
    "X,y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape #1797 images, 64 pixels per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values in array present grey values in the image\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not very informative so we should plot the image itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first image. We need to reshape the 64 pixels into [8,8] array\n",
    "plt.imshow(X[0].reshape(8,8),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "<h4> Exercise 1.</h4>  Make a function `plot` taking an argument (k) to visualize the k'th sample. \n",
    "It is currently flattened, you will need to reshape it. Use `plt.imshow` for plotting and add title of the number the image presents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test your solution\n",
    "plot(15); plot(450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Olivetti face data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dataset of 40 subjects faces with varying facial expressions, facial details and lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "<h4>Exercise 2. </h4> Inspect the dataset. How many classes are there? How many samples per class? Also, plot some examples. What do the classes represent? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "*Hint: Write `faces.` and press tab to see what attributes dataset has.*    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have made yourself familiar with the dataset we can do some data exploration with unsupervised methods, like below. The next few lines of code are simply for illustration, don't worry about the code (we will cover unsupervised methods in submodule F)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = faces.data\n",
    "y = faces.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 3\n",
    "u, s, v = randomized_svd(X, n_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have factorized the images into their constituent parts. The code below displays the various components isolated one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't worry about this code\n",
    "def show_ims(ims):\n",
    "    fig = plt.figure(figsize=(16,10))\n",
    "    idxs = [0,1,2, 11,12,13, 40,41,42, 101,101,103]\n",
    "    for i,k in enumerate(idxs):\n",
    "        ax=fig.add_subplot(3,4,i+1)\n",
    "        ax.imshow(ims[k])\n",
    "        ax.set_title(f\"target={y[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_dim):\n",
    "    my_s = np.zeros(s.shape[0])\n",
    "    my_s[i] = s[i]\n",
    "    recon = u@np.diag(my_s)@v\n",
    "    recon = recon.reshape(400,64,64)\n",
    "    show_ims(recon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you able to see what the components represent? It at least looks like the second component signifies the lightning  (the light direction), the third highlights eyebrows and facial chin shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import TSNE which is clustering algorithm we can use to find groups from our data. We will learn more about this in Part 3 of this course when we dive deeper into machine learning and clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(init='pca', random_state=0)\n",
    "trans = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 8*10 # choose 4 people\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "xs, ys = trans[:m,0], trans[:m,1]\n",
    "plt.scatter(xs, ys, c=y[:m], cmap='rainbow')\n",
    "\n",
    "for i,v in enumerate(zip(xs,ys, y[:m])):\n",
    "    xx,yy,s = v \n",
    "    #plt.text(xx,yy,s) #class\n",
    "    plt.text(xx,yy,i) #index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many people seem to have multiple subclusters. What is the difference between those clusters? (e.g. 68,62,65 versus the other 60's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(im):\n",
    "    return plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ims = faces.images\n",
    "\n",
    "idxs = [68,62,65,66,60,64,63]\n",
    "#idxs = [9,4,1, 5,3]\n",
    "for k in idxs:\n",
    "    show(ims[k])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid impact on airport traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle** has lots of datasets to play with. Here we load data of traffic volume post-COVID in various airports. https://www.kaggle.com/datasets/terenceshin/covid19s-impact-on-airport-traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv from kaggle\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://www.kaggle.com/datasets/terenceshin/covid19s-impact-on-airport-traffic/download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we don't need\n",
    "df = df.drop(columns = ['AggregationMethod','Version','Centroid','ISO_3166_2','Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's analyze only Australia\n",
    "data_au = df[df['Country']=='Australia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by date\n",
    "data_au = data_au.sort_values(by=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date as index\n",
    "data_au.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_au.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot percent of baseline over time\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(data_au['PercentOfBaseline'])\n",
    "plt.xticks(range(0,300,25))\n",
    "plt.title(\"Plot for PercentOfBaseline Vs Time for Australia\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Fetching an OpenML dataset\n",
    "\n",
    "Here we will look at [OpenML](https://www.openml.org/) - a repository of open datasets free to explore data and test methods.\n",
    "\n",
    "We need to pass in an ID to access, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenML contains all sorts of datatypes. By browsing the website we found a electroencephalography (EEG) dataset to explore: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = 1471 #this was found by browsing OpenML\n",
    "dataset = fetch_openml(data_id=data_id, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_names=['AF3', 'F7', 'F3', 'FC5', 'T7', 'P', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0] / 117\n",
    "# 128 frames per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def summary(s):\n",
    "#    print(s.max(), s.min(), s.mean(), s.std())\n",
    "#    print()\n",
    "#    \n",
    "#for col in df.columns[:-1]:\n",
    "#    column = df.loc[:,col]\n",
    "#    summary(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can quickly identify a bunch of huge outliers, making the plot look completely uselss. We assume these are artifacts, and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[:,:-1].clip(upper=6000) #Elements above the threshold will be changed to match the threshold value.\n",
    "df2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see better what is going on. Lets just remove the frames corresponding to those outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which are the frames that are above 5000\n",
    "frames = np.nonzero(np.any(df.iloc[:,:-1].values>5000, axis=1))[0] \n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove those frames\n",
    "df.drop(index=frames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting without outliers\n",
    "df.plot(figsize=(16,8))\n",
    "plt.legend(labels=original_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression estimates the probability of an event occurring, based on a given dataset of independent variables. Since the outcome is a probability, the dependent variable is bounded between 0 and 1. We will look regression closer later in this course but here is short example with the previous data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make logistic regression model\n",
    "lasso = LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# divide into X and y (data ie. EEG measurements and target ie. eyes open/closed)\n",
    "X = df.values[:,:-1]\n",
    "y = df.Class\n",
    "\n",
    "y = y.astype(np.int) - 1 # map to 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with our data (=train model to classify samples using EEG values)\n",
    "lasso.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict y values with the model\n",
    "comp = (lasso.predict(X) == y).values\n",
    "np.sum(comp.astype(np.int))/y.shape[0] # accuracy of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is not very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print coefficients\n",
    "coef = lasso.coef_[0]\n",
    "plt.barh(range(coef.shape[0]), coef)\n",
    "plt.yticks(ticks=range(14),labels=original_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the coeficients: we naturally tend to read the magnitude of the coefficients as feature importance. So in that case P and T7 values have most impact to y. That is a fair interpretation, but currently we did not scale our features to a comparable range prior to fitting the model, so we cannot draw that conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "Go to [OpenML](https://openml.org) and use the search function (or just look around) to find any dataset that interest you. Load it using the above methodology, and try to do anything you can to understand the datatype, visualize it etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
