{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-commentate"
    ]
   },
   "source": [
    "# Open datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquiring Data from open repositories\n",
    "\n",
    "A crucial step in the work of a computational biologist is not only to analyse data, but acquiring datasets to analyse as well as toy datasets to test out computational methods and algorithms. The internet is full of such open datasets. Sometimes you have to sign up and make a user to get authentication, especially for medical data. This can sometimes be time consuming, so here we will deal with easy access resources, mostly of modest size. Multiple python libraries provide a `dataset` module which makes the effort to fetch online data extremely seamless, with little requirement for preprocessing.\n",
    "\n",
    "\n",
    "### Goal of the notebook\n",
    "\n",
    "Here you will get familiar with some ways to fetch datasets from online. We do some data exploration on the data just for illustration, but the methods will be covered later.\n",
    "\n",
    "\n",
    "# Useful resources and links\n",
    "\n",
    "When playing around with algorithms, it can be practical to use relatively small datasets. A good example is the `datasets` submodule of `scikit-learn`. `Nilearn` (library for neuroimaging) also provides a collection of neuroimaging datasets. Many datasets can also be acquired through the competition website [Kaggle](https://www.kaggle.com), in which they describe how to access the data.\n",
    "\n",
    "\n",
    "### Links\n",
    "- [OpenML](https://www.openml.org/search?type=data)\n",
    "- [Nilearn datasets](https://nilearn.github.io/modules/reference.html#module-nilearn.datasets)\n",
    "- [Sklearn datasets](https://scikit-learn.org/stable/modules/classes.html?highlight=datasets#module-sklearn.datasets)\n",
    "- [Kaggle](https://www.kaggle.com/datasets)\n",
    "- [MEDNIST]\n",
    "\n",
    "-  [**Awesomedata**](https://github.com/awesomedata/awesome-public-datasets)\n",
    "\n",
    " - We strongly recommend to check out the Awesomedata lists of public datasets, covering topics such as [biology/medicine](https://github.com/awesomedata/awesome-public-datasets#biology) and [neuroscience](https://github.com/awesomedata/awesome-public-datasets#neuroscience)\n",
    "\n",
    "- [Papers with code](https://paperswithcode.com)\n",
    "\n",
    "- [SNAP](https://snap.stanford.edu/data/)\n",
    "  - Stanford Large Network Dataset Collection  \n",
    "- [Open Graph Benchmark (OGB)](https://github.com/snap-stanford/ogb)\n",
    "  - Network datasets\n",
    "- [Open Neuro](https://openneuro.org/)\n",
    "- [Open fMRI](https://openfmri.org/dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with scikit-learn's datasets for testing out Machine Learning (ML) algorithms. Visit [here](https://scikit-learn.org/stable/modules/classes.html?highlight=datasets#module-sklearn.datasets) for an overview of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiple datasets from sklearn package. These are functions we can call to get said dataset\n",
    "from sklearn.datasets import fetch_olivetti_faces, fetch_20newsgroups, load_breast_cancer, load_diabetes, load_digits, load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Hand written digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset that consists of images of hand written digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data (pixels) to X and target (the number the image represents) to y\n",
    "X,y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape #1797 images, 64 pixels per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values in array are grey values of the image (0=black, 15=white)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y has the labels, i.e. pixels above represent the number in same index in y\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first image. We need to reshape the 64 pixels into [8,8] array\n",
    "plt.imshow(X[0].reshape(8,8), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "<h4> Exercise 1.</h4>  Make a function `plot()` taking an argument (k) to visualize the k'th sample. \n",
    "It is currently flattened, you will need to reshape it. Use `plt.imshow` for plotting and add title of the number the image presents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test your solution\n",
    "plot(15); plot(450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Olivetti face data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dataset of 40 subjects faces with varying facial expressions, facial details and lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "<h4>Exercise 2. </h4> Inspect the dataset. How many classes are there? How many samples per class? Also, plot some examples. What do the classes represent? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "*Hint: Write `faces.` and press tab to see what attributes dataset has.*    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have made yourself familiar with the dataset we can do some data exploration with unsupervised methods, like below. The next few lines of code are simply for illustration, don't worry about the code (we will cover unsupervised methods in submodule F)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = faces.data\n",
    "y = faces.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 3\n",
    "u, s, v = randomized_svd(X, n_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have factorized the images into their constituent parts. The code below displays the various components isolated one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't worry about this code\n",
    "def show_ims(ims):\n",
    "    fig = plt.figure(figsize=(16,10))\n",
    "    idxs = [0,1,2, 11,12,13, 40,41,42, 101,101,103]\n",
    "    for i,k in enumerate(idxs):\n",
    "        ax=fig.add_subplot(3,4,i+1)\n",
    "        ax.imshow(ims[k])\n",
    "        ax.set_title(f\"target={y[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_dim):\n",
    "    my_s = np.zeros(s.shape[0])\n",
    "    my_s[i] = s[i]\n",
    "    recon = u@np.diag(my_s)@v\n",
    "    recon = recon.reshape(400,64,64)\n",
    "    show_ims(recon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components highlight different features of the image. Are you able to see what features the components represent? It at least looks like the second component signifies the lightning  (the light direction), the third highlights eyebrows and facial chin shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-activity"
    ]
   },
   "source": [
    "# Fetching an OpenML dataset\n",
    "\n",
    "Here we will look at [OpenML](https://www.openml.org/) - a repository of open datasets free to explore data and test methods.\n",
    "\n",
    "We need to pass in an ID to access, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenML contains all sorts of datatypes. By browsing the website we found a electroencephalography (EEG) dataset to explore: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = 1471 #this was found by browsing OpenML\n",
    "dataset = fetch_openml(data_id=data_id, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_names=['AF3', 'F7', 'F3', 'FC5', 'T7', 'P', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0] / 117\n",
    "# 128 frames per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can quickly identify a bunch of huge outliers, making the plot look completely uselss. We assume these are artifacts, and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[:,:-1].clip(upper=6000) #Elements above the threshold will be changed to match the threshold value.\n",
    "df2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see better what is going on. Lets just remove the frames corresponding to those outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which are the frames that are above 5000\n",
    "frames = np.nonzero(np.any(df.iloc[:,:-1].values>5000, axis=1))[0] \n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove those frames\n",
    "df.drop(index=frames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting without outliers\n",
    "df.plot(figsize=(16,8))\n",
    "plt.legend(labels=original_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
