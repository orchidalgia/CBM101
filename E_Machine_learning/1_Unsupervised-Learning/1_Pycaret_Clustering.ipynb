{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830365f0",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b2980",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "One of the most common use cases in unsupervised machine learning is the identification of clusters - discrete groups of samples which are somehow closer related to samples within the same cluster than they are with those outside. Once we abstract our data in to a general *d*-dimensional space of N samples, we can quickly start to apply our intuition to how to determine cluster membership. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0552c6",
   "metadata": {},
   "source": [
    "You may be wondering which clustering algorithm is the best to find \"natural subgroups\" in your data? Well, the nature of the data will answer that question:\n",
    "- For example, a large dataset could preclude computationally intensive algorithms (e.g *hierarchical clustering* or *affinity propagation*). \n",
    "- Is anything known about the underlying structure (e.g. globular versus non-globular)? \n",
    "- Are you looking for a specific number of clusters? \n",
    "- So, unfortunately, you need to have various algorithms in your toolbox, ready to deploy as the circumstances dictate \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a9864c",
   "metadata": {},
   "source": [
    "![title](./assets/scatter-2d.png)\n",
    "\n",
    "**If you were to manually group the data in the above graph, how would you do it?**<br>\n",
    "    You might draw two circles, like this:\n",
    "    \n",
    "![title](./assets/scatter-2d-circled.png)    \n",
    "\n",
    "And this is what we obtain using an appropriate clustering algorithm (e.g. Gaussian mixture model (GMM)):\n",
    "\n",
    "![title](./assets/scatter-2d-segments.png)\n",
    "\n",
    "But before delving into advanced models like GMM, we have to introduce the basics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e10f5b",
   "metadata": {},
   "source": [
    "## K-means\n",
    "\n",
    "This is the most fundamental clustering algorithm. \n",
    "\n",
    "<img src=\"assets/KMeans_animation.gif\" style=\"float:left\"/>\n",
    "\n",
    "Assuming we know *a priori* the number of clusters (k), the algorithm starts by placing k coordinates (centroides c) in the feature space. First all samples are assigned to their closest centroid. Once assigned, we update the centroid location as the mean of all the samples belonging to it. These steps are allowed to continue until convergence.\n",
    "\n",
    "The final result depends on where the starting coordinates are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb30364",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.clustering import *\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_blobs # to generate new datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f4dad",
   "metadata": {},
   "source": [
    "## Make simple dataset for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create points on 4 clusters\n",
    "# X has the data points (coordinates) and y has classes\n",
    "X, y = make_blobs(n_samples=200, centers=4, random_state=42, cluster_std=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b7b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the example data\n",
    "    \n",
    "# call that function to draw a scatterplot    \n",
    "sns.scatterplot(X[:,0], X[:,1], y, palette='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3109f1cc",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <h4> Exercise 1. a)</h4> Create a new dataset that has 180 samples, 5 clusters, 3 features and standard deviation is 1,2. Use random_state=42\n",
    "    <h4> b)</h4> Plot the first and third features of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex1 a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f290b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/pyc_1a.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex2 b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d4af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/pyc_1b.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ce4b83",
   "metadata": {},
   "source": [
    "# Pycaret\n",
    "\n",
    "Pycaret is a low-code and beginner-friendly machine learning (ML) library in Python that automates and speeds up the ML-workflow. Pycaret replaces hundreds of lines of code with only a few."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc0d964",
   "metadata": {},
   "source": [
    "## Clustering in Pycaret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bbc983",
   "metadata": {},
   "source": [
    "PyCaret's clustering module provides several pre-processing features that can be configured when initializing the setup through the `setup()` function. It has several algorithms and plots to analyze the results. PyCaret's clustering module also implements a unique function called `tune_model()` that allows you to tune the hyperparameters of a clustering model to optimize a supervised learning objective such as R^2 for regression.\n",
    "\n",
    "`setup()` is Pycaret's main function and it **needs to be run before executing any other function** in pycaret. The `setup()` function initializes the environment in pycaret and creates the transformation pipeline to prepare the data for modeling and deployment.\n",
    "\n",
    "When `setup()` is executed, PyCaret's inference algorithm will automatically infer the data types for all features based on certain properties. Ensuring that the data types are correct is of fundamental importance in PyCaret as it automatically performs a few pre-processing tasks which are imperative to any machine learning experiment. These tasks are performed differently for each data type which means it is very important for them to be correctly configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8161ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup() has lots of optional parameters for e.g. preprocessing, but let's run it with defaults\n",
    "s = setup(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93317cca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pycaret offers many clustering algorithms we can compare\n",
    "models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0625580",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c4582",
   "metadata": {},
   "source": [
    "Next let's create and train a kmeans model. Without additional parameters it will use 4 clusters as default but if you know the number of clusters beforehand you can pass it using `num_clusters` parameter. In this case we know there is supposed to be 5 clusters and we're gonna use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = create_model('kmeans', num_clusters=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a89ddf",
   "metadata": {},
   "source": [
    "Pycaret will print some useful metrics. Silhouette Coefficient or silhouette score is a metric used to calculate the goodness of a clustering technique. Its value ranges from -1 to 1, where 1 means that clusters are well apart from each other and clearly distinguished, 0 means that clusters are indifferent ie. the distance between clusters is not significant, and -1 means that clusters are assigned in the wrong way.\n",
    "\n",
    "We can plot silhouette scores per cluster and get validation of consistency within clusters of data. The technique provides a succinct graphical representation of how well each object has been classified. In other words, the silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ef78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(kmeans, plot = 'silhouette')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b20472",
   "metadata": {},
   "source": [
    "Another useful method is the **elbow method**, which is a heuristic method of interpretation and validation of consistency within cluster analysis designed to **help find the appropriate number of clusters** in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858bc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(kmeans, plot = 'elbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa29a4d",
   "metadata": {},
   "source": [
    "In this example the Elbow plot above suggests that 3 is the optimal number of clusters. Usually there is a clear angle, *elbow*, in the distortion scores, and that cutoff point is where adding another cluster doesn't give much better modeling of the data. You can use this suggestion to create a new model, but in this case we know there should be 5 clusters and we used that previously so we're not gonna create another model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1e9b3",
   "metadata": {},
   "source": [
    "### Centroids \n",
    "\n",
    "The **model** here is a python *object*, and can thus have certain attributes, such as the centroids locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(X[:, 0], X[:, 1], color='gray')\n",
    "sns.scatterplot(centroids[:, 0], centroids[:, 1], s=200, marker=\"X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd393192",
   "metadata": {},
   "source": [
    "## Plot the model results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d7a6d",
   "metadata": {},
   "source": [
    "The `plot_model()` function can be used to analyze different aspects of the clustering model. This function takes a trained model object and returns a plot. See examples below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b220cd",
   "metadata": {},
   "source": [
    "### PCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbcacc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_model(kmeans, plot = 'cluster') #cluster is default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e7077",
   "metadata": {},
   "source": [
    "### Distribution plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c069e2",
   "metadata": {},
   "source": [
    "The distribution plot shows the size of each cluster. When hovering over the bars you will see the number of samples assigned to each cluster. We can also use the distribution plot to see the distribution of cluster labels in association with any other numeric or categorical feature. Features are column names of your dataframe, but in this case *feature_1* has been autogenerated since column names weren't passed. See an example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ff845",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(kmeans, plot = 'distribution', feature='feature_1') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7578de1a",
   "metadata": {},
   "source": [
    "## Compare to original clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002cde6",
   "metadata": {},
   "source": [
    "Normally you wouldn't be able to compare clusters since you don't have anything to compare. In this case we know the original clusters and we can therefore compare kmeans results to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1ce07",
   "metadata": {},
   "source": [
    "Predicted clusters are saved in the model object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00efe823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = kmeans.labels_\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure size\n",
    "plt.figure(figsize=(12,5)) \n",
    "\n",
    "# original clusters\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(X[:,0], X[:,1],hue=y, palette='viridis').set(title='Original clusters')\n",
    "\n",
    "# predicted clusters\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(X[:,0], X[:,1],hue=pred, palette='viridis').set(title='Predicted clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5acdc",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <h4> Exercise 2.</h4> Calculate how well predicted clusters match the originals. \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e403e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load solutions/pyc_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140cc7a4",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <h4> Exercise 3.</h4> Create another model (run <b>model()</b> to see available models) and see if it can predict clusters better than kmeans.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af468b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
