# Unsupervised learning

Out of the two major divisions of ML, this one is concerned with finding latent patterns in data. The defining feature is that we train the algorithms on unlabeled data, which means the algorithms must learn implicitly, aided by nothing but the raw samples themselves. A number of applications exist for unsupervised learning: identifying groups of similar samples, data compression, denoising, as a preprocessing step (feature engineering) prior to supervised learning, and for visualization purposes. In more advanced usecases it can be used in generative modelling as well.

The most common use cases are **clustering** (grouping together similar samples), and **dimensionality reduction** techniques. A vast array of unsupervised ML algorthms exist, each with their own pros and cons. Knowing when to use which is a very useful skill to have as a data scientist. The practical applications for unsupervised learning reach far and wide, such as in face recognition software and cleaning/separating signals from brain EEG scans.



Below is an example of a clustering task.
<img src="assets/scatter-2d-circled.png">